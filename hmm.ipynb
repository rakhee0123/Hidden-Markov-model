{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d51641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hmmlearn in c:\\users\\91900\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\91900\\anaconda3\\lib\\site-packages (from hmmlearn) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in c:\\users\\91900\\anaconda3\\lib\\site-packages (from hmmlearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\91900\\anaconda3\\lib\\site-packages (from hmmlearn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\91900\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91900\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hmmlearn\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import seaborn as sns  \n",
    "from tqdm import tqdm  \n",
    "from matplotlib import pyplot as plt  \n",
    "  \n",
    "from sklearn.model_selection import GroupShuffleSplit  \n",
    "from hmmlearn import hmm  \n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e68ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"NER dataset.csv\", encoding='latin1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea7feb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.fillna(method=\"ffill\")  \n",
    "dataset = dataset.rename(columns={'Sentence #': 'sentence'})  \n",
    "dataset.head(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df28eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 35178)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(dataset.POS.values))  \n",
    "words = list(set(dataset.Word.values))  \n",
    "len(tags), len(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99b47efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.POS  \n",
    "X = dataset.drop('POS', axis=1)  \n",
    "  \n",
    "groupshufflesplit = GroupShuffleSplit(n_splits=2, test_size=.33, random_state=42)  \n",
    "ix_train, ix_test = next(groupshufflesplit.split(X, y,groups=dataset['sentence']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49dbb9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702936 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sentence       Word  POS Tag\n",
       "24           Sentence: 2   Families  NNS   O\n",
       "25           Sentence: 2         of   IN   O\n",
       "26           Sentence: 2   soldiers  NNS   O\n",
       "27           Sentence: 2     killed  VBN   O\n",
       "28           Sentence: 2         in   IN   O\n",
       "...                  ...        ...  ...  ..\n",
       "1048570  Sentence: 47959       they  PRP   O\n",
       "1048571  Sentence: 47959  responded  VBD   O\n",
       "1048572  Sentence: 47959         to   TO   O\n",
       "1048573  Sentence: 47959        the   DT   O\n",
       "1048574  Sentence: 47959     attack   NN   O\n",
       "\n",
       "[702936 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = dataset.loc[ix_train]  \n",
    "dataset_test = dataset.loc[ix_test]  \n",
    "  \n",
    "dataset_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76081bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 29587)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(dataset_train.POS.values))  \n",
    "words = list(set(dataset_train.Word.values))  \n",
    "len(tags), len(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ab781b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 27554)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_update = dataset_train.sample(frac=.15, replace=False, random_state=42)\n",
    "dataframe_update.Word = 'UNKNOWN'  \n",
    "dataset_train.update(dataframe_update)  \n",
    "words = list(set(dataset_train.Word.values))  \n",
    "# Convert words and tags into numbers  \n",
    "word2id = {w: i for i, w in enumerate(words)}  \n",
    "tag2id = {t: i for i, t in enumerate(tags)}  \n",
    "id2tag = {i: t for i, t in enumerate(tags)}  \n",
    "len(tags), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "189f6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_count = dict(dataset_train.POS.value_counts())  \n",
    "tags_to_word_count = dataset_train.groupby(['POS']).apply(lambda grp: grp.groupby('Word')['POS'].count().to_dict()).to_dict()  \n",
    "init_tags_count = dict(dataset_train.groupby('sentence').first().POS.value_counts())\n",
    "tags_to_next_tags_count = np.zeros((len(tags), len(tags)), dtype=int)  \n",
    "sentences = list(dataset_train.sentence)  \n",
    "pos = list(dataset_train.POS)  \n",
    "for i in range(len(sentences)) :  \n",
    "    if (i > 0) and (sentences[i] == sentences[i - 1]):  \n",
    "        prevtagid = tag2id[pos[i - 1]]  \n",
    "        nexttagid = tag2id[pos[i]]  \n",
    "        tags_to_next_tags_count[prevtagid][nexttagid] += 1  \n",
    "  \n",
    "my_start_prob = np.zeros((len(tags),))  \n",
    "my_transmat = np.zeros((len(tags), len(tags)))  \n",
    "my_emission_prob = np.zeros((len(tags), len(words)))  \n",
    "num_sentences = sum(init_tags_count.values())  \n",
    "sum_tags_to_next_tags = np.sum(tags_to_next_tags_count, axis=1)  \n",
    "for tag, tagid in tag2id.items():  \n",
    "    floatCountTag = float(tags_count.get(tag, 0))  \n",
    "    my_start_prob[tagid] = init_tags_count.get(tag, 0) / num_sentences  \n",
    "    for word, wordid in word2id.items():  \n",
    "        my_emission_prob[tagid][wordid]= tags_to_word_count.get(tag, {}).get(word, 0) / floatCountTag  \n",
    "    for tag2, tagid2 in tag2id.items():  \n",
    "        my_transmat[tagid][tagid2]= tags_to_next_tags_count[tagid][tagid2] / sum_tags_to_next_tags[tagid] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a470caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    }
   ],
   "source": [
    "n_components = len(tags)\n",
    "model = hmm.MultinomialHMM(n_components=42, algorithm='viterbi', random_state=42)  \n",
    "model.startprob_ = my_start_prob  \n",
    "model.transmat_ = my_transmat  \n",
    "model.emissionprob_ = my_emission_prob  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c339fee4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cheated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10300\\4247812446.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msamples_of\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0msamples_of\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#TODO use panda solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cheated'"
     ]
    }
   ],
   "source": [
    "test_word = list(dataset_test.Word)  \n",
    "samples_of = []  \n",
    "for i, val in enumerate(test_word):  \n",
    "        samples_of.append([word2id[val]])\n",
    "\n",
    "#TODO use panda solution  \n",
    "lengths = []  \n",
    "count = 0  \n",
    "sentences = list(dataset_test.sentence)  \n",
    "for i in range(len(sentences)) :  \n",
    "    if (i > 0) and (sentences[i] == sentences[i - 1]):  \n",
    "        count += 1  \n",
    "    elif i > 0:  \n",
    "        lengths.append(count)  \n",
    "        count = 1  \n",
    "    else:  \n",
    "        count = 1  \n",
    "  \n",
    "#This code is very slow  \n",
    "predict_pos = model.predict(samples_of, lengths)  \n",
    "predict_pos  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c957067",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_test = list(dataset_test.POS)  \n",
    "pos_test = np.zeros((len(tags_test), ), dtype=int)  \n",
    "for i, val in enumerate(tags_test):  \n",
    "    pos_test[i] = tag2id[val]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3542d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportTest(y_pred, y_test):  \n",
    "    print(\"The accuracy is {}\".format(accuracy_score(y_test, y_pred)))  \n",
    "    print(\"The precision is {}\".format(precision_score(y_test, y_pred, average='weighted')))\n",
    "    print(\"The recall is {}\".format(recall_score(y_test, y_pred, average='weighted'))) \n",
    "    print(\"The F1-Score is {}\".format(f1_score(y_test, y_pred, average='weighted')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69d5677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 1.0\n",
      "The precision is 1.0\n",
      "The recall is 1.0\n",
      "The F1-Score is 1.0\n"
     ]
    }
   ],
   "source": [
    "min_length = min(len(pos_test), len(pos_test))  \n",
    "  \n",
    "reportTest(pos_test[:min_length], pos_test[:min_length])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2cb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
